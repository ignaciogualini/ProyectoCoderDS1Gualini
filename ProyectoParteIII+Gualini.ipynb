{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Abstract ai jobs proyect:\n",
        "El presente proyecto se centra en el análisis de un dataset de ofertas laborales en el área de IA, que incluye información sobre título del puesto, ubicación, experiencia requerida, tipo de contrato, nivel de trabajo remoto, tamaño de la empresa, habilidades solicitadas, educación requerida, industria, beneficios y salario en dólares estadounidenses.\n",
        "\n",
        "La elección de este dataset responde al interés de comprender los factores que influyen en la remuneración de profesionales del sector, un área donde las competencias técnicas, la localización y la experiencia pueden tener un peso significativo. El objetivo principal es identificar patrones y relaciones entre las características del puesto y el salario ofrecido, y sentar las bases para un modelo predictivo que permita estimar el salario en función de dichas variables.\n",
        "\n",
        "El análisis se desarrollará en varias etapas: identificación y tratamiento de valores perdidos, exploración de las distribuciones y relaciones entre variables, creación de visualizaciones multivariadas y cálculo de medidas estadísticas. Este enfoque permitirá responder preguntas clave como:\n",
        "\n",
        "\n",
        "*   ¿qué nivel de experiencia está mejor remunerado?\n",
        "*   ¿cuál es la influencia del trabajo remoto?\n",
        "*   ¿importa más la localización de la empresa o la residencia del empleado?\n",
        "\n",
        "\n",
        "Los hallazgos obtenidos no solo aportarán información útil para quienes buscan oportunidades laborales en IA, sino también para empresas que desean establecer bandas salariales competitivas. En futuras fases, el proyecto evolucionará hacia la construcción de un modelo para la predicción de salarios, integrando las conclusiones obtenidas en esta etapa inicial.\n"
      ],
      "metadata": {
        "id": "BxZVrpfEfdgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split, ValidationCurveDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "M2E1Ko_nfezq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino el dataframe a partir de la url y separo las features del target\n",
        "url = 'https://raw.githubusercontent.com/ignaciogualini/Proyecto_Coder_DS1_Gualini/refs/heads/main/datasets/ai_job_dataset.csv'\n",
        "ai_jobs_df = pd.read_csv(url, index_col='job_id')\n",
        "target = 'salary_usd'\n",
        "X, y = (ai_jobs_df.drop(columns=target), ai_jobs_df[target])\n",
        "ai_jobs_df.head()"
      ],
      "metadata": {
        "id": "ETFUXUJBf7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preguntas de investigación:\n",
        "\n",
        "1. **¿Cómo afecta la experiencia al salario?**\n",
        "2. **¿Qué impacto tiene el tamaño de la empresa en el salario?**\n",
        "3. **¿Existe alguna relación entre el salario y el trabajo remoto?**\n",
        "4. **¿Por qué algunos salarios son extremadamente altos y qué factores los explican?¿Son outliers?**\n",
        "---\n",
        "### Hipótesis:\n",
        "\n",
        "*  H1. A mayor experiencia, mayor será el salario.\n",
        "*  H2. Las empresas grandes (`L`) ofrecen salarios más altos que las medianas (`M`) y pequeñas (`S`).\n",
        "*  H3. Sería de esperar que esta variable (`remote_ratio`) no tenga peso alguno en el salario.\n",
        "*  H4. Los salarios extremadamente altos corresponden a roles senior o especializados, con muchos años de experiencia y alto nivel de `experience_level`."
      ],
      "metadata": {
        "id": "b7_asDGqWusB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'El dataframe a analizar se compone de {ai_jobs_df.shape[0]} filas y {ai_jobs_df.shape[1]} columnas\\n')\n",
        "print(f'La cantidad de valores nulos por columna es:\\n\\n {ai_jobs_df.isnull().sum()}')"
      ],
      "metadata": {
        "id": "rcQ-fk5-gUXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separo las columnas numéricas de las categóricas\n",
        "num_col_selector = make_column_selector(dtype_exclude=object)\n",
        "cat_col_selector = make_column_selector(dtype_include=object) # Use object to include categorical columns\n",
        "num_cols = num_col_selector(X)\n",
        "cat_cols = cat_col_selector(X)\n",
        "X_num = X[num_cols]\n",
        "X_cat = X[cat_cols]\n",
        "print(f'De estas {ai_jobs_df.shape[1]} columnas, 1 es el target (salario en USD), {len(num_cols)} son numéricas y {len(cat_cols)} son categóricas')"
      ],
      "metadata": {
        "id": "2zqjtA_liIgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'También podemos realizar una breve descripción estadística de sus columnas numéricas:\\n\\n{X_num.describe()}')\n",
        "print(f'\\nPodemos observar que algunas de las columnas numéricas poseen valores mucho mayores a otras,\\npor lo que no es descabellado pensar en una futura estandarización.')\n",
        "print(f'\\nEn cuanto al target:\\n\\n{y.describe()}')"
      ],
      "metadata": {
        "id": "hr89b31QhYHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo una matriz de correlación para el mapa de calor\n",
        "correlation = ai_jobs_df[num_cols + [target]].corr()\n",
        "_ = sns.heatmap(correlation, cmap='Reds', annot=True, linewidths=.5, linecolor='black')\n",
        "print('Gráfico 1')"
      ],
      "metadata": {
        "id": "oAonlFw8ereB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras realizar un análisis de correlación entre variables numéricas, se puede observar que ninguna de ellas guarda relación más que consigo misma. Por lo que no tenemos columnas numéricas que sean redundantes para el análisis.\n",
        "\n",
        "También se ve que el target (`salary_usd`) posee una correlación fuerte con los años de experiencia. Por lo que se confirma que es una buena hipótesis a plantear y a resolver en los siguientes gráficos."
      ],
      "metadata": {
        "id": "QQEFvR-hetwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'La variable remote_ratio solo posee {X_num[\"remote_ratio\"].nunique()} valores únicos ({X_num[\"remote_ratio\"].unique()}), por lo que podríamos usar esta informacion en un gráfico.\\n')\n",
        "\n",
        "# Categorizo la variable \"company_size\" para que aparezca en el orden deseado de tamaño\n",
        "# X['company_size'] = pd.Categorical(X['company_size'], categories=['S', 'M', 'L'], ordered=True)\n",
        "print(f'Por otro lado, la variable \"company_size\" posee los valores {list(X[\"company_size\"].unique())}\\n')\n",
        "\n",
        "print('Gráfico 2.1/Gráfico 2.2')\n",
        "\n",
        "color_map = {'S': 'black', 'M': 'blue', 'L': 'red'}\n",
        "\n",
        "# Divido el gráfico en dos ejes separados en dos columnas\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n",
        "\n",
        "# Línea de tendencia para ax1\n",
        "sns.regplot(\n",
        "    ax=ax1,\n",
        "    data=ai_jobs_df,\n",
        "    x='years_experience',\n",
        "    y=target,\n",
        "    scatter=False,\n",
        "    line_kws={'color': 'black'},\n",
        "    label='línea de tendencia',\n",
        "    )\n",
        "\n",
        "# Gráfico de dispersión para ax1\n",
        "sc1 = ax1.scatter(\n",
        "    X_num['years_experience'],\n",
        "    y,\n",
        "    c=X_num['remote_ratio'],\n",
        "    cmap='plasma',\n",
        "    alpha=1,\n",
        "    edgecolors='w',\n",
        "    linewidth=0.5,\n",
        ")\n",
        "ax1.set_xlabel('Años de experiencia')\n",
        "ax1.set_ylabel('Salario en USD')\n",
        "ax1.set_title('Relación Experiencia vs Salario con Remote Ratio')\n",
        "plt.colorbar(sc1, label='Remote Ratio')\n",
        "ax1.legend()\n",
        "\n",
        "# Línea de tendencia para ax2\n",
        "sns.regplot(\n",
        "    ax=ax2,\n",
        "    data=ai_jobs_df,\n",
        "    x='years_experience',\n",
        "    y=target,\n",
        "    scatter=False,\n",
        "    line_kws={'color': 'black'},\n",
        "    label='línea de tendencia',\n",
        "    )\n",
        "\n",
        "# Gráfico de dispersión para ax2\n",
        "sc2 = ax2.scatter(\n",
        "    X_num['years_experience'],\n",
        "    y,\n",
        "    c=X['company_size'].map(color_map),\n",
        "    alpha=0.8\n",
        ")\n",
        "ax2.set_xlabel('Años de experiencia')\n",
        "ax2.set_ylabel('Salario en USD')\n",
        "ax2.set_title('Relación Experiencia vs Salario con Tamaño de empresa')\n",
        "plt.colorbar(sc2, label='Company size')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tq7Ik6HgjfHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente, existe una relación positiva entre los años de experiencia de un trabajador y su salario.\n",
        "En cuanto a la variable `remote_ratio`, podemos ver que en cada columna del gráfico a la izquierda (2.1) los colores se distribuyen de forma variada, lo cual indica que el Remote Ratio no está tan correlacionado directamente con el salario.\n",
        "\n",
        "Realizando este mismo análisis en el gráfico de la derecha (2.2), en cada columna se puede observar cierta tendencia: los puntos rojos suelen estar más arriba y los de color negro abajo, por lo cual existe cierta relación positiva entre el salario de un trabajador y el tamaño de la empresa (`company_size`). Entendiendo que mientras más grande sea la empresa, mejor va a pagar a sus empleados."
      ],
      "metadata": {
        "id": "PhdNfVXcaLYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = ['job_description_length', 'benefits_score', 'years_experience'] # Defino variables de interés para la función de figura\n",
        "print('Gráfico 3')\n",
        "\n",
        "# Paso a formato largo para que mi FacetGrid lo entienda\n",
        "df_long = X.melt(\n",
        "    id_vars=['company_size'],\n",
        "    value_vars=variables,\n",
        "    var_name='variable',\n",
        "    value_name='valor'\n",
        ")\n",
        "\n",
        "# Utilizo una función de figura donde las columnas se representen por el tamaño de la compañía\n",
        "# En cada fila se encuentran las variables de interés\n",
        "g = sns.FacetGrid(\n",
        "    df_long,\n",
        "    row='variable',\n",
        "    col='company_size',\n",
        "    margin_titles=True,\n",
        "    sharex=False,\n",
        "    sharey=False\n",
        ")\n",
        "\n",
        "g.map(sns.histplot, 'valor', bins=20, color='blue', edgecolor='black', kde=True)\n",
        "\n",
        "g.set_titles(row_template='{row_name}', col_template='{col_name}')\n",
        "g.set_axis_labels('', \"Frecuencia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tT8gVva73ZgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando los histogramas, podemos concluir lo siguiente:\n",
        "la distribución de cada variable numérica (exceptuando \"remote ratio\") es independiente al tamaño de empresa.\n",
        "Por lo que estas variables no están sesgadas en función a si una empresa es grande, mediana o chica.\n",
        "\n",
        "Este tipo de análisis resulta conveniente en estas situaciones, ya que cuando dos variables o features están correlacionadas fuertemente aportan información redundante, y complican la interpretación del modelo.\n",
        "Un claro ejemplo de esto son las columnas `experience_level` y `years_experience`, ya que apuntan a lo mismo."
      ],
      "metadata": {
        "id": "jrgh0-h7bFtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 4.1/Gráfico 4.2')\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Divido el gráfico en dos ejes separados en dos columnas\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), sharey=False)\n",
        "\n",
        "# Elaboro un boxplot para ax1\n",
        "sns.boxplot(data=ai_jobs_df, y=target, ax=ax1)\n",
        "ax1.axhline(y=y.mean(), color='red', linestyle='--', linewidth=2, label=f'Salario medio: ${y.mean():.2f}')\n",
        "ax1.axhline(y=y.mean() - y.std(), color='blue', linestyle='--', linewidth=2, label=f'Límite inferior: ${(y.mean() - y.std()):.2f}')\n",
        "ax1.axhline(y=y.mean() + y.std(), color='green', linestyle='--', linewidth=2, label=f'Límite superior: ${(y.mean() + y.std()):.2f}')\n",
        "ax1.set_ylabel('Salario en USD')\n",
        "ax1.set_title('Boxplot')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Elaboro un histograma para ax2\n",
        "sns.histplot(data=ai_jobs_df, x=target, ax=ax2, bins=20, edgecolor='black', kde=True)\n",
        "ax2.axvline(x=y.mean(), color='red', linestyle='--', linewidth=2,)\n",
        "ax2.axvline(x=y.mean() - y.std(), color='blue', linestyle='--', linewidth=2,)\n",
        "ax2.axvline(x=y.mean() + y.std(), color='green', linestyle='--', linewidth=2,)\n",
        "ax2.set_xlabel('Salario en USD')\n",
        "ax2.set_ylabel('Cantidad')\n",
        "ax2.set_title('Histograma')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "_ = plt.suptitle('Distribución de salarios')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 0.95, 1])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('\\nSe puede ver en el gráfico de caja que tenemos muchos valores por fuera de 1.5IQR. Esto puede llegar a indicar que son outliers.')\n",
        "print('Si analizamos el histograma, vemos que hay una distribución sesgada a la derecha típica de variables salariales:\\nla mayoría gana entre un rango bajo/medio, pero hay una minoría con salarios muy altos.')\n",
        "print('Entonces se puede decir que estos valores son parte natural de la distribución y no un error de registro. Son casos válidos y aportan información relevante para el posterior modelo.')\n",
        "print(f'Esto también va de la mano con el valor de la desviación estándar: {y.std():.1f} $. En proporción, es el {((y.std() / y.mean()) * 100):.2f} % del salario medio, indicando un valor considerable para este parámetro.\\nEsto se relaciona con la distribución sesgada a la derecha, ya que hay muchos valores lejanos a la media.\\n')"
      ],
      "metadata": {
        "id": "IA1Nld8V6wqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conclusiones preliminares en función de las hipótesis:\n",
        "\n",
        "*  ***H1. A mayor experiencia, mayor será el salario:***\n",
        "el mapa de calor (*Gráfico 1*) así como la gráfica de dispersión y la línea de regresión (*Gráficos 2.1 y 2.2*) confirman la relación positiva que guardan estas dos variables, confirmando la hipótesis n° 1✅.\n",
        "\n",
        "*  ***H2. Las empresas grandes (`L`) ofrecen salarios más altos que las medianas (`M`) y pequeñas (`S`):***\n",
        "En el segundo gráfico de dispersión (*Gráfico 2.2*) se puede observar que en cada columna los puntos rojos suelen estar más arriba y los de color negro abajo, por lo cual existe cierta relación positiva entre el salario de un trabajador y el tamaño de la empresa. Esto confirma la hipótesis n° 2✅.\n",
        "\n",
        "*  ***H3. Sería de esperar que esta variable (`remote_ratio`) no tenga peso alguno en el salario:***\n",
        "Los colores por `remote_ratio` en el primer gráfico de dispersión (*Gráfico 2.1*) no muestran un patrón claro ni correlación fuerte con el salario.\n",
        "Esto sugiere que el nivel de trabajo remoto no es un factor determinante por sí solo para el salario. Hipótesis confirmada✅.\n",
        "\n",
        "*  ***H4. Los salarios extremadamente altos corresponden a roles senior o especializados, con muchos años de experiencia y alto nivel de `experience_level`:***\n",
        "Este apartado va de la mano con la primera hipótesis. En el boxplot (*Gráfico 4.1*) podemos ver que **estadísticamente** tenemos varios outliers. Pero si realizamos un análisis en conjunto con el histograma (*Gráfico 4.2*) los valores altos no son outliers ni errores de medición, son una representación fiel de una distribución sesgada a la derecha. Esta brecha salarial (y a su vez, desviación estándar considerable) es común en este tipo de empleos donde existen muchos factores que generen diferencia en cuanto al pago.\n"
      ],
      "metadata": {
        "id": "lqcqfKml1kqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(i) Feature selection:\n",
        "En lo que respecta a las variables numéricas, se realizó un análisis preliminar con el objetivo de identificar aquellas que pudieran tener una relación lineal con la variable objetivo (salario). Para ello se construyó un mapa de calor de correlaciones de Pearson, considerando las variables `job_description_length`, `remote_ratio` y `benefits_score`, junto con el target.\n",
        "\n",
        "Esto permite cuantificar el grado de asociación lineal entre dos variables numéricas, facilitando la detección de posibles redundancias o irrelevancias en el conjunto de datos. En este caso, los valores de correlación obtenidos mostraron una relación débil o prácticamente nula entre dichas variables y el salario, lo que sugiere que no aportan información significativa al modelo predictivo.\n",
        "\n",
        "En consecuencia, estas variables fueron descartadas del dataset final, con el fin de reducir el ruido, simplificar la dimensionalidad y evitar que características poco informativas afecten el desempeño del modelo."
      ],
      "metadata": {
        "id": "uEg2D5X-Okjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 5')\n",
        "irrelevant_num_cols = ['job_description_length', 'remote_ratio', 'benefits_score']\n",
        "correlation = ai_jobs_df[irrelevant_num_cols + [target]].corr()\n",
        "_ = sns.heatmap(correlation, cmap='Blues', annot=True, linewidths=.5, linecolor='black')"
      ],
      "metadata": {
        "id": "Zb9prglnVoqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuanto a las variables categóricas, también se llevó a cabo un proceso de depuración con el objetivo de reducir ruido y evitar redundancias en el dataset. En primer lugar, se descartaron las variables `salary_currency`, `application_deadline` y `posting_date`, ya que no guardan una relación directa con el salario esperado ni aportan información relevante para la predicción. Este tipo de atributos, al no estar vinculados conceptualmente con la naturaleza del problema, tienden a introducir variabilidad innecesaria y pueden dificultar el aprendizaje del modelo.\n",
        "\n",
        "Por otro lado, se eliminaron las variables `experience_level` y `required_skills`, dado que su información ya se encuentra representada de forma más detallada en otras características: `years_experience` y `job_title`, respectivamente. Mantener ambas versiones de la misma información habría implicado redundancia y riesgo de colinealidad, lo cual afecta la interpretabilidad y estabilidad de los modelos de regresión.\n",
        "\n",
        "En síntesis, el descarte de estas variables categóricas respondió a un criterio de relevancia y no redundancia, priorizando aquellas que mejor representan la relación con el target y contribuyen a la construcción de un modelo más robusto y eficiente."
      ],
      "metadata": {
        "id": "iNec3433QWK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupo las features a droppear\n",
        "drop_cols = ['job_description_length', 'remote_ratio', 'benefits_score','salary_currency', 'application_deadline', 'posting_date', 'experience_level', 'required_skills']\n",
        "X_fs = X.drop(columns=drop_cols)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fs, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separación de columnas categóricas y numéricas desde el dataset con las características relevantes\n",
        "num_cols_fs = num_col_selector(X_fs)\n",
        "cat_cols_fs = cat_col_selector(X_fs)\n",
        "\n",
        "# Orden jerárquico de las variables categóricas\n",
        "company_size_order = [[\"S\", \"M\", \"L\"]]\n",
        "education_order = [[\"Associate\", \"Bachelor\", \"Master\", \"PhD\"]]\n",
        "\n",
        "# Separo variables categóricas en funcion de OneHot o OrdinalEncoder (orden jerárquico)\n",
        "hierarch_cat = ['company_size', 'education_required']\n",
        "onehot_cat = [cat for cat in cat_cols_fs if cat not in hierarch_cat]"
      ],
      "metadata": {
        "id": "Ah3BCFBjwOtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(ii) Elección de algoritmo\n",
        "En esta etapa se procede a la elección del algoritmo de regresión, con el objetivo de capturar de la mejor manera posible la relación entre las variables explicativas y el salario en dólares estadounidenses. En primer lugar, se optó por utilizar Ridge Regression (con y sin estandarización de columnas numéricas), un modelo lineal regularizado que resulta adecuado cuando el dataset contiene un gran número de variables y potencial multicolinealidad entre ellas. La penalización L2 que incorpora este algoritmo ayuda a reducir la varianza y evitar el sobreajuste, manteniendo al mismo tiempo una buena interpretabilidad de los coeficientes.\n",
        "\n",
        "No obstante, al tratarse de un problema de alta dimensionalidad con interacciones complejas entre variables, también se exploró un enfoque más flexible: la combinación de Nystroem Kernel Approximation con Ridge Regression. Esta técnica permite proyectar los datos a un espacio de mayor complejidad a través de un mapeo no lineal, pero de manera eficiente en términos computacionales gracias a la aproximación de Nystroem. De esta forma, se logra capturar relaciones no lineales en los datos sin recurrir a algoritmos más pesados como Support Vector Regression o redes neuronales.\n",
        "\n",
        "La comparación entre ambos enfoques permitirá evaluar si el incremento en complejidad (Nystroem + Ridge) se traduce en una mejora significativa en la capacidad predictiva respecto al modelo lineal regularizado (Ridge simple).\n",
        "\n",
        "Vale aclarar que toda la elección del algoritmo se llevará a cabo con el conjunto de prueba X_train, y_train; reservando el conjunto X_test, y_test para la evaluación del modelo final con distintas métricas."
      ],
      "metadata": {
        "id": "qM1wFMztTzyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Ridge no estandarizado\n",
        "preproc_non_std = ColumnTransformer(\n",
        "    transformers=[\n",
        "    ('hierarch_preproc', OrdinalEncoder(categories=[*company_size_order, *education_order]), hierarch_cat),\n",
        "    ('onehot_preproc', OneHotEncoder(handle_unknown='ignore'), onehot_cat),\n",
        "    ('num_preproc', 'passthrough', num_cols_fs)]\n",
        ")\n",
        "\n",
        "pipe_non_std = Pipeline(steps=[\n",
        "    ('preproc', preproc_non_std),\n",
        "    ('Ridge reg', Ridge())\n",
        "])"
      ],
      "metadata": {
        "id": "waGtAT2yS-6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_non_std = cross_validate(\n",
        "    pipe_non_std,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=10,\n",
        "    return_estimator=True,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    return_train_score=True,\n",
        "    error_score='raise',\n",
        ")\n",
        "cv_non_std = pd.DataFrame(cv_non_std)\n",
        "cv_non_std"
      ],
      "metadata": {
        "id": "_ILN-5neNiC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Ridge estandarizado\n",
        "preproc_std = ColumnTransformer(\n",
        "    transformers=[\n",
        "    ('hierarch_preproc', OrdinalEncoder(categories=[*company_size_order, *education_order]), hierarch_cat),\n",
        "    ('onehot_preproc', OneHotEncoder(handle_unknown='ignore'), onehot_cat),\n",
        "    ('num_preproc', StandardScaler(), num_cols_fs)\n",
        "])\n",
        "\n",
        "pipe_std = Pipeline(steps=[\n",
        "    ('preproc', preproc_std),\n",
        "    ('Ridge reg', Ridge())\n",
        "])"
      ],
      "metadata": {
        "id": "tBW8xVomTCyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_std = cross_validate(\n",
        "    pipe_std,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=10,\n",
        "    return_estimator=True,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    return_train_score=True,\n",
        "    error_score='raise'\n",
        ")\n",
        "cv_std = pd.DataFrame(cv_std)\n",
        "cv_std"
      ],
      "metadata": {
        "id": "rXZY91-zNvyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Ridge utilizando Nystroem como aproximación de Kernel proveniente del módulo .kernel_approximation\n",
        "# El objetivo es generar columnas de grado 3, así el modelo puede captar mejor las relaciones no lineales entre las features. Esto le da más expresividad.\n",
        "preproc_nyst = ColumnTransformer(transformers=[\n",
        "    ('hierarch_preproc', OrdinalEncoder(categories=[*company_size_order, *education_order]), hierarch_cat),\n",
        "    ('onehot_preproc', OneHotEncoder(handle_unknown='ignore'), onehot_cat),\n",
        "    ('num_preproc', 'passthrough', num_cols_fs)\n",
        "])\n",
        "pipe_nystroem = Pipeline(steps=[\n",
        "    ('preproc', preproc_nyst),\n",
        "    ('Nystroem', Nystroem(kernel='poly', degree=3, n_components=1000)),\n",
        "    ('Ridge reg', Ridge())\n",
        "])"
      ],
      "metadata": {
        "id": "e6_fyZM7EtZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_std_nyst = cross_validate(\n",
        "    pipe_nystroem,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=10,\n",
        "    return_estimator=True,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    return_train_score=True,\n",
        ")\n",
        "cv_std_nyst = pd.DataFrame(cv_std_nyst)\n",
        "cv_std_nyst"
      ],
      "metadata": {
        "id": "1CZEWg5MODlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente se procederá a graficar una curva de validación para cada modelo presentado previamente. Se analizará la variación del MAE en función del hiperparámetro en cuestión (alpha)."
      ],
      "metadata": {
        "id": "biP_9g1-VWOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_range = np.logspace(-3, 3, 6)\n",
        "\n",
        "# Modulo la creación de la curva de validación\n",
        "def alpha_validation_curve(model, title: str, cv=10):\n",
        "  disp = ValidationCurveDisplay.from_estimator(\n",
        "      model,\n",
        "      X_train,\n",
        "      y_train,\n",
        "      cv=cv,\n",
        "      scoring='neg_mean_absolute_error',\n",
        "      negate_score=True,\n",
        "      param_name='Ridge reg__alpha',\n",
        "      param_range=param_range,\n",
        "      n_jobs=2,\n",
        "  )\n",
        "\n",
        "  disp.ax_.set(xlabel='alpha', ylabel='mean absolute error', title=title)"
      ],
      "metadata": {
        "id": "5aiT2kC6TfMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 6.1')\n",
        "alpha_validation_curve(pipe_non_std, title='Curva de validación de Modelo de Ridge no estandarizado')"
      ],
      "metadata": {
        "id": "V2yTINp-Tleu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 6.2')\n",
        "alpha_validation_curve(pipe_std, title='Curva de validación del Modelo de Ridge estandarizado')"
      ],
      "metadata": {
        "id": "mmfIEEIPTmUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 6.3')\n",
        "alpha_validation_curve(pipe_nystroem, title='Curva de validación del Modelo de Ridge + Nystroem')"
      ],
      "metadata": {
        "id": "F21S-xzHTmYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, no existe mucha diferencia entre el Gráfico 6.1 y 6.2. Esto es debido a que no hay necesidad de escalar características numéricas, pues la variable `years_experience` ya está originalmente en una escala comparable a las de las variables categóricas al ser preprocesadas por OneHot o por OrdinalEncoder.\n",
        "Por otro lado, podemos ver que en la curva de validación perteneciente al último modelo, el error absoluto llega a ser alrededor de casi un 10 % menor en relación a los dos primeros modelos. Esto puede deberse a que, al ser un modelo más expresivo que los anteriores, se captaron relaciones no lineales que se correlacionaban con la variable objetivo `salary_usd`. Podría haberse utilizado también Polynomial Features, pero la dimensionalidad hubiese aumentado, haciendo al modelo costoso computacionalmente hablando."
      ],
      "metadata": {
        "id": "_RHffL-JWWHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuadro resumen de la validación cruzada de 10 pasos para cada modelo\n",
        "mae_summary = pd.DataFrame({\n",
        "    'non_std_Ridge': cv_non_std['test_score'],\n",
        "    'std_Ridge': cv_std['test_score'],\n",
        "    'std_nystroem_Ridge': cv_std_nyst['test_score']\n",
        "})\n",
        "# Append a new row with the mean values using .loc\n",
        "mae_summary.loc['mean'] = {\n",
        "    'non_std_Ridge': mae_summary['non_std_Ridge'].mean(),\n",
        "    'std_Ridge': mae_summary['std_Ridge'].mean(),\n",
        "    'std_nystroem_Ridge': mae_summary['std_nystroem_Ridge'].mean()\n",
        "}\n",
        "mae_summary"
      ],
      "metadata": {
        "id": "PKbEAJFpInTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Habiendo empleado la curva de validación (variación del hiperparámetro alpha) y el cuadro resumen de la validación cruzada (hiperparámetros fijos), se concluye que el modelo más adecuado para este dataset es el Modelo de Ridge sobre espacio transformado por Nystroem.\n",
        "Posteriormente se hará un análisis de hiperparámetros para encontrar aquellos que sean más aptos para este caso."
      ],
      "metadata": {
        "id": "R-Bu0uUecBtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_comp_range = np.logspace(2, 3, 5).astype(int)\n",
        "param_grid = {\n",
        "    'Ridge reg__alpha': param_range,\n",
        "    'Nystroem__n_components': n_comp_range\n",
        "}\n",
        "\n",
        "model_grid = GridSearchCV(pipe_nystroem, param_grid, cv=10, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "model_grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "NIiITamVry-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = pd.DataFrame(model_grid.cv_results_)\n",
        "cv_results"
      ],
      "metadata": {
        "id": "pJNaANOBsffH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuadro resumen del score medio (-MAE) en función de la variación de alpha y del número de componentes del kernel aproximado\n",
        "col_results = [f'param_{name}' for name in param_grid.keys()]\n",
        "col_results.append('mean_test_score')\n",
        "cv_res = pd.DataFrame(model_grid.cv_results_)[col_results]\n",
        "cv_res.sort_values(by='mean_test_score', ascending=False)\n",
        "\n",
        "def shorten_name(name):\n",
        "  if '__' in name:\n",
        "    return name.split('__')[1]\n",
        "  return name\n",
        "\n",
        "cv_res.columns = [shorten_name(col) for col in cv_res.columns]\n",
        "cv_res"
      ],
      "metadata": {
        "id": "DkEM8OAx0XDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gráfico 7')\n",
        "px.parallel_coordinates(\n",
        "    cv_res.apply({\n",
        "        'alpha': lambda x: np.log10(x),\n",
        "        'n_components': lambda x: x,\n",
        "        'mean_test_score': lambda x: x\n",
        "    }),\n",
        "    color='mean_test_score',\n",
        "    color_continuous_scale=px.colors.sequential.Inferno,\n",
        ")"
      ],
      "metadata": {
        "id": "r10rTeP1y_CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el Gráfico 7 (gráfico de coordenadas paralelas) se puede apreciar la variación de la métrica utilizada para el scoring (-MAE) en relación a los rangos utilizados para ambos hiperparámetros en el GridSearchCV. Es posible interactuar con los ejes para elegir cierto rango y ver qué resultados otorga."
      ],
      "metadata": {
        "id": "KlVcLVMQfGED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_alpha = model_grid.best_params_['Ridge reg__alpha']\n",
        "best_n_comp = model_grid.best_params_['Nystroem__n_components']\n",
        "print(f'Los mejores hiperparámetros para el modelo son alpha = {best_alpha:.3f} y n_components = {best_n_comp}')"
      ],
      "metadata": {
        "id": "c6N0kcIr7Cso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model_grid.best_estimator_\n",
        "best_model"
      ],
      "metadata": {
        "id": "dKihqfkS7jza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##(iii) Cálculo de métricas para validar el modelo\n",
        "A continuación se emplearán distintas métricas para la validación final del modelo. Cabe recordar que estas validaciones se harán con el dataset apartado inicialmente para el test: X_test, y_test.\n",
        "Las métricas a utilizar son:\n",
        "* `Error medio absoluto`: mide la magnitud promedio de los errores entre los valores reales y los valores predichos por el modelo, sin considerar su dirección (+/-).\n",
        "* `Error medio cuadrático`: mide la diferencia al cuadrado entre los valores reales y los valores predichos por el modelo, siendo el promedio de estas diferencias.\n",
        "* `r2`: indica la proporción de variabilidad en la variable dependiente que puede ser explicada por las variables independientes en el modelo."
      ],
      "metadata": {
        "id": "5kV945pbgAyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se modula la validación cruzada para un modelo y métrica determinado\n",
        "def cv_metric_test(model, metric: str):\n",
        "\n",
        "  cv_metric = cross_validate(\n",
        "      model,\n",
        "      X_test,\n",
        "      y_test,\n",
        "      cv=10,\n",
        "      scoring=metric,\n",
        "      n_jobs=-1,\n",
        "      return_train_score=True,\n",
        "  )\n",
        "  return cv_metric['test_score'].mean()"
      ],
      "metadata": {
        "id": "ALDOKn0fkBf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = cv_metric_test(best_model, 'neg_mean_absolute_error')\n",
        "r2 = cv_metric_test(best_model, 'r2')\n",
        "mse = cv_metric_test(best_model, 'neg_mean_squared_error')\n",
        "\n",
        "print(f'El MAE del modelo final es: {-mae:.2f} USD')\n",
        "print(f'El R2 del modelo final es: {r2:.2f}')\n",
        "print(f'El MSE del modelo final es: {-mse:.2f} USD^2')"
      ],
      "metadata": {
        "id": "ziiv6mH6ksGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desempeño del modelo final se evaluó sobre un conjunto de prueba independiente, obteniéndose un MAE de aproximadamente 17.500 USD, un MSE de 607.000.000 USD² y un R² de 0,83. Dado que el salario medio en el dataset es de 115.000 USD, el MAE representa alrededor del 15 % del salario medio, lo que indica que, en promedio, las predicciones se desvían moderadamente del valor real. Por otro lado, la raíz del MSE (RMSE ≈ 24.600 USD) refleja que los errores grandes, influenciados por valores salariales extremos, siguen siendo razonables considerando la dispersión del dataset.\n",
        "\n",
        "En conjunto, estas métricas muestran que el modelo capta correctamente la mayor parte (83 %) de la variabilidad de los salarios y resulta útil para estimaciones aproximadas de rangos salariales de profesionales de IA. Sin embargo, no se recomienda usarlo para predicciones exactas en casos individuales debido a la presencia de valores atípicos y la variabilidad natural de los salarios en este sector."
      ],
      "metadata": {
        "id": "hm_N4YrDnrTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (iv) Conclusiones finales\n",
        "\n",
        "### Relación entre variables y salario\n",
        "\n",
        "* Se confirmó que los años de experiencia y el tamaño de la empresa son los factores con mayor influencia sobre el salario, tal como se planteó en las hipótesis iniciales.\n",
        "\n",
        "* La proporción de trabajo remoto (`remote_ratio`) no mostró un impacto significativo en los salarios, mientras que variables categóricas como `education_required` o `company_size` aportan información útil cuando se codifican de manera jerárquica.\n",
        "\n",
        "### Selección de características\n",
        "\n",
        "* Se descartaron variables irrelevantes o redundantes como `job_description_length`, `experience_level`, `required_skills` y fechas de publicación, reduciendo la dimensionalidad y evitando ruido para el modelo.\n",
        "Esto, a su vez, condujo a la reducción de features y permitió manejar más eficientemente la codificación one-hot, facilitando el entrenamiento de modelos complejos como Ridge con Nystroem.\n",
        "\n",
        "###Elección de modelos y transformación no lineal\n",
        "\n",
        "* Se compararon tres enfoques: Ridge lineal sin estandarizar, Ridge lineal estandarizado y Ridge sobre features transformadas por Nystroem.\n",
        "\n",
        "* La transformación Nystroem permitió capturar relaciones no lineales entre las variables y el salario, logrando la menor magnitud de error (MAE ≈ 17.500 USD) y un R² elevado (≈0,83), mejorando ligeramente el desempeño respecto al Ridge lineal. También se confirmo que no siempre es necesaria una estandarización de datos numéricos.\n",
        "\n",
        "###Evaluación del desempeño\n",
        "\n",
        "* Las métricas obtenidas indican que el modelo es capaz de explicar la mayor parte de la variabilidad del salario en el dataset y ofrece estimaciones razonables para rangos salariales.\n",
        "\n",
        "* La presencia de salarios extremos (outliers) limita la precisión de predicciones individuales, pero estos casos son consistentes con la distribución real del mercado laboral en IA.\n",
        "\n",
        "###Aplicaciones y utilidad del modelo\n",
        "\n",
        "* El modelo es útil para estimaciones generales de salarios según experiencia, educación y tamaño de la empresa. Puede servir como referencia para profesionales que buscan oportunidades laborales y para empresas que desean establecer bandas salariales competitivas en roles de IA.\n",
        "\n",
        "En resumen, el proyecto demuestra que, aun con un dataset con variables categóricas mayoritarias y algunos valores extremos, es posible construir un modelo robusto capaz de capturar patrones relevantes del mercado salarial en IA, y que la combinación de Ridge con Nystroem ofrece una mejora clara al incorporar relaciones no lineales entre las features."
      ],
      "metadata": {
        "id": "LULIa5TApbNR"
      }
    }
  ]
}